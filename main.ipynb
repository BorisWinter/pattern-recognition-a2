{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pattern Recognition pipeline\n",
    "The entire pipeline should be runnable from here.\n",
    "\n",
    "### Genes data\n",
    "**Raw genes data**\n",
    "- Data is expected to be in *raw_data/genes/data.csv*\n",
    "- Labels are expected to be in *raw_data/genes/labels.csv*\n",
    "\n",
    "### Image data\n",
    "**Raw image data**\n",
    "- Animal images are expected to be in *raw_data/BigCats/[Animal]/*\n",
    "\n",
    "### Feature selection\n",
    "- Feature selection functions can be found in *feature_selection/[function].py*\n",
    "\n",
    "### Classification\n",
    "- Classification functions can be found in *classification/[function].py*\n",
    "\n",
    "### Clustering\n",
    "- Clustering functions can be found in *clustering/[function].py*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import ALL required imports\n",
    "\n",
    "# Ignore SKlearn's deprecation warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "# Data imports\n",
    "from raw_data.data_functions import load_num_data, load_img_data,load_img_data_2dim\n",
    "from raw_data.data_load_MI_SVM import getImageData\n",
    "\n",
    "# Feature selection imports\n",
    "from feature_selection.pca import pca\n",
    "from feature_selection.MI import MI_feature_select\n",
    "from feature_selection.fourier_transform import ft_on_img_data\n",
    "from feature_selection.edge_detection import edge_detection\n",
    "from feature_selection.SIFT import build_center,cal_vec\n",
    "\n",
    "# Classification imports\n",
    "from classification.knn import knn, knn_gridsearch, knn_cross_validation\n",
    "from classification.svm import svm_genes,svm_images,svm_images_gridsearch,svm_images_cross_val\n",
    "from classification.decision_tree import decision_tree, cross_val_decision_tree\n",
    "from classification.logistic_regression import logistic_regression, logistic_regression_cross_validation, logistic_regression_gridsearch\n",
    "\n",
    "# Clustering imports\n",
    "from clustering.kmeans import kmeans_train\n",
    "from clustering.fuzzy_c_means import fuzzy_c_means # pip install fuzzy-c-means\n",
    "\n",
    "# Misc imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from visualization.visualization import create_conf_matrix\n",
    "from visualization.visualization import simple_pca_line_plot\n",
    "from visualization.visualization import plot_tsne_num\n",
    "from visualization.visualization import plot_tsne_img\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading num data...\n",
      "Loading img data...\n",
      "Loading img2 data...\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading num data...\")\n",
    "num_data, num_labels = load_num_data()\n",
    "print(\"Loading img data...\")\n",
    "img_data, img_labels = load_img_data()\n",
    "print(\"Loading img2 data...\")\n",
    "img_data_2, img_labels_2=load_img_data_2dim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Data\n",
    "**Create t-SNE embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data_embedded = TSNE(n_components=2, learning_rate='auto', init='random', random_state=0).fit_transform(num_data)\n",
    "img_data_embedded = TSNE(n_components=2, learning_rate='auto', init='random', random_state=0).fit_transform(img_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the t-SNE embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genes data\n",
    "# title = \"t-SNE visualization of the Genes data\"\n",
    "# xlabel = \"t-SNE dimension 1\"\n",
    "# ylabel = \"t-SNE dimension 2\"\n",
    "# plot_tsne_num(num_data_embedded, num_labels, title, xlabel, ylabel)\n",
    "\n",
    "# BigCats data\n",
    "# title = \"t-SNE visualization of the BigCats data\"\n",
    "# xlabel = \"t-SNE dimension 1\"\n",
    "# ylabel = \"t-SNE dimension 2\"\n",
    "# plot_tsne_img(img_data_embedded, img_labels, title, xlabel, ylabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA\n",
    "**Apply PCA to the Genes data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_num_data = pca(num_data.iloc[:,1:])\n",
    "\n",
    "# Plot the cumulative variance explained per number of principal components\n",
    "# simple_pca_line_plot(\n",
    "#     pca_model.explained_variance_ratio_.cumsum()[:], \n",
    "#     title=\"Cum. variance explained / # principal components\",\n",
    "#     ylabel=\"Ratio of variance explained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perform PCA experiment with k-NN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result storage\n",
    "pca_knn_res = []\n",
    "\n",
    "# Perform cross-validated k-NN for each possible number of components\n",
    "for num_components in range(1,802):\n",
    "    selected_data = pca_num_data.iloc[:,:num_components]\n",
    "    acc, f1 = knn_cross_validation(selected_data, num_labels[1], 3)\n",
    "    pca_knn_res.append(acc)\n",
    "\n",
    "# Plot the result\n",
    "# simple_pca_line_plot(\n",
    "#     pca_knn_res[:], \n",
    "#     title=\"Test accuracy per number of principal components\",\n",
    "#     ylabel=\"Test accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reduce PCA data to the most useful components (=79)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_num_data_red = pca_num_data.iloc[:,:80]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature selection start\n",
      "Feature drop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abe/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "478 features whose MI score over threshold are selected from 20531 features\n",
      "feature selection end\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mi_num_data=MI_feature_select(num_data,num_labels,thre=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SIFT  80/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary saved: (50, 128)\n",
      "data_vec: (136, 50)\n",
      "image features extration done!\n"
     ]
    }
   ],
   "source": [
    "X_train_sift, X_test_sift, y_train_sift, y_test_sift = train_test_split(img_data_2, img_labels_2,test_size=0.2,random_state=77,stratify=img_labels_2)\n",
    "build_center(X_train_sift) # the input data should be training data\n",
    "data_vec_8020,labels_8020 = cal_vec(X_train_sift, y_train_sift) # the input data should be training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fourier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_img_data = ft_on_img_data(img_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contour Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_img_data = edge_detection(img_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-NN - Genes - 80/20 split\n",
    "**Raw data (best k = 15 [0.998090, 0.998437])**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.9937888198757764 - F1-score = 0.993758020635491\n"
     ]
    }
   ],
   "source": [
    "# Create the 80/20 split\n",
    "x_train, x_test, y_train, y_test = train_test_split(num_data, num_labels, test_size=0.2, random_state=42, stratify=num_labels)\n",
    "\n",
    "# Tune k using gridsearch on the train set\n",
    "# knn_gridsearch(x_train, y_train[1], [k for k in range(1,21,2)])\n",
    "\n",
    "# Train using the optimal k (=5) and test on the test set\n",
    "acc, f1, pred_labels = knn(x_train, y_train[1], x_test, y_test[1], k=15)\n",
    "print(f'Accuracy = {acc} - F1-score = {f1}')\n",
    "\n",
    "# Show a confusion matrix\n",
    "# create_conf_matrix(y_test[1], pred_labels,  title=\"k-NN predictions using raw data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PCA (best k = 13 [0.998785, 0.998437])**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.9813664596273292 - F1-score = 0.9811987061061624\n"
     ]
    }
   ],
   "source": [
    "# Create the 80/20 split\n",
    "x_train, x_test, y_train, y_test = train_test_split(pca_num_data_red, num_labels, test_size=0.2, random_state=42, stratify=num_labels)\n",
    "\n",
    "# Tune k using gridsearch on the train set\n",
    "# knn_gridsearch(x_train, y_train[1], [k for k in range(1,21,2)])\n",
    "\n",
    "# Train using the optimal k (=k) and test on the test set\n",
    "acc, f1, pred_labels = knn(x_train, y_train[1], x_test, y_test[1], k=13)\n",
    "print(f'Accuracy = {acc} - F1-score = {f1}')\n",
    "\n",
    "# Show a confusion matrix\n",
    "# create_conf_matrix(y_test[1], pred_labels,  title=\"k-NN predictions using PCA data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mutual Information (best k = 5 [0.998437, 0.998437])**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.9937888198757764 - F1-score = 0.993758020635491\n"
     ]
    }
   ],
   "source": [
    "# Create the 80/20 split\n",
    "x_train, x_test, y_train, y_test = train_test_split(mi_num_data, num_labels, test_size=0.2, random_state=42, stratify=num_labels)\n",
    "\n",
    "# Tune k using gridsearch on the train set\n",
    "# knn_gridsearch(x_train, y_train[1], [k for k in range(1,21,2)])\n",
    "\n",
    "# Train using the optimal k (=k) and test on the test set\n",
    "acc, f1, pred_labels = knn(x_train, y_train[1], x_test, y_test[1], k=5)\n",
    "print(f'Accuracy = {acc} - F1-score = {f1}')\n",
    "\n",
    "# Show a confusion matrix\n",
    "# create_conf_matrix(y_test[1], pred_labels, title=\"k-NN predictions using MI data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mutual Information (best k = 5 [0.998437, 0.998437])**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the 80/20 split\n",
    "x_train, x_test, y_train, y_test = train_test_split(mi_num_data, num_labels, test_size=0.2, random_state=42, stratify=num_labels)\n",
    "\n",
    "# Tune k using gridsearch on the train set\n",
    "# knn_gridsearch(x_train, y_train[1], [k for k in range(1,21,2)])\n",
    "\n",
    "# Train using the optimal k (=k) and test on the test set\n",
    "acc, f1, pred_labels = knn(x_train, y_train[1], x_test, y_test[1], k=5)\n",
    "print(f'Accuracy = {acc} - F1-score = {f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-NN - Genes - Cross Validation\n",
    "**Raw data (best k = 3,5,7,9 [0.998752, 0.998750])**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.99875 - F1-score = 0.9987370977534912\n"
     ]
    }
   ],
   "source": [
    "# Tune k using gridsearch on the entire data set\n",
    "# knn_gridsearch(num_data, num_labels[1], [k for k in range(1,21,2)])\n",
    "\n",
    "# Evaluate with the optimal k (=k) using cross validation\n",
    "acc, f1 = knn_cross_validation(num_data, num_labels[1], k=3)\n",
    "print(f'Accuracy = {acc} - F1-score = {f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PCA (best k = 3 [0.997503, 0.997500])**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.9974999999999999 - F1-score = 0.9974441687344914\n"
     ]
    }
   ],
   "source": [
    "# Tune k using gridsearch on the entire data set\n",
    "# knn_gridsearch(pca_num_data_red, num_labels[1], [k for k in range(1,21,2)])\n",
    "\n",
    "# Evaluate with the optimal k (=k) using cross validation\n",
    "acc, f1 = knn_cross_validation(pca_num_data_red, num_labels[1], k=3)\n",
    "print(f'Accuracy = {acc} - F1-score = {f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mutual Information (best k = 5-19 [0.997503, 0.997500])**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.9974999999999999 - F1-score = 0.9974441687344914\n"
     ]
    }
   ],
   "source": [
    "# Tune k using gridsearch on the entire data set\n",
    "# knn_gridsearch(mi_num_data, num_labels[1], [k for k in range(1,21,2)])\n",
    "\n",
    "# Evaluate with the optimal k (=k) using cross validation\n",
    "acc, f1 = knn_cross_validation(mi_num_data, num_labels[1], k=5)\n",
    "print(f'Accuracy = {acc} - F1-score = {f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-NN - BigCats - 80/20 split\n",
    "**Raw data (best k = 3 [0.520405, 0.235714])**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.17647058823529413 - F1-score = 0.16657329598506068\n"
     ]
    }
   ],
   "source": [
    "# Create the 80/20 split\n",
    "x_train, x_test, y_train, y_test = train_test_split(img_data, img_labels, test_size=0.2, random_state=42, stratify=img_labels)\n",
    "\n",
    "# Tune k using gridsearch on the train set\n",
    "# knn_gridsearch(x_train, y_train, [k for k in range(1,21,2)])\n",
    "\n",
    "# Train using the optimal k (=k) and test on the test set\n",
    "acc, f1, pred_labels = knn(x_train, y_train, x_test, y_test, k=3)\n",
    "print(f'Accuracy = {acc} - F1-score = {f1}')\n",
    "\n",
    "# Show a confusion matrix\n",
    "# create_conf_matrix(y_test, pred_labels, title=\"k-NN predictions using raw data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SIFT (best k = k)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.5357142857142857 - F1-score = 0.4932686361257789\n"
     ]
    }
   ],
   "source": [
    "# # Create the 80/20 split\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_vec_8020, labels_8020, test_size=0.2, random_state=42, stratify=labels_8020)\n",
    "\n",
    "# # Tune k using gridsearch on the train set\n",
    "# # knn_gridsearch(x_train, y_train, [k for k in range(1,21,2)])\n",
    "\n",
    "# # Train using the optimal k (=5) and test on the test set\n",
    "acc, f1, pred_labels = knn(x_train, y_train, x_test, y_test, k=7)\n",
    "print(f'Accuracy = {acc} - F1-score = {f1}')\n",
    "\n",
    "# # Show a confusion matrix\n",
    "# create_conf_matrix(y_test, pred_labels, title=\"k-NN predictions using SIFT data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fourier (best k = 17 [0.361922, 0.300549])**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.4411764705882353 - F1-score = 0.3927932576539388\n"
     ]
    }
   ],
   "source": [
    "# Create the 80/20 split\n",
    "x_train, x_test, y_train, y_test = train_test_split(ft_img_data, img_labels, test_size=0.2, random_state=42, stratify=img_labels)\n",
    "\n",
    "# Tune k using gridsearch on the train set\n",
    "# knn_gridsearch(x_train, y_train, [k for k in range(1,21,2)])\n",
    "\n",
    "# Train using the optimal k (=5) and test on the test set\n",
    "acc, f1, pred_labels = knn(x_train, y_train, x_test, y_test, k=17)\n",
    "print(f'Accuracy = {acc} - F1-score = {f1}')\n",
    "\n",
    "# Show a confusion matrix\n",
    "# create_conf_matrix(y_test, pred_labels, title=\"k-NN predictions using FT data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-NN - BigCats - Cross Validation\n",
    "**Raw data (best k = 7 [0.384967, 0.247059])**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.24705882352941178 - F1-score = 0.2068569992099404\n"
     ]
    }
   ],
   "source": [
    "# Tune k using gridsearch on the entire data set\n",
    "# knn_gridsearch(img_data, img_labels, [k for k in range(1,21,2)])\n",
    "\n",
    "# Evaluate with the optimal k (=k) using cross validation\n",
    "acc, f1 = knn_cross_validation(img_data, img_labels, k=7)\n",
    "print(f'Accuracy = {acc} - F1-score = {f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SIFT (best k = k)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.4791208791208791 - F1-score = 0.4430913134484563\n"
     ]
    }
   ],
   "source": [
    "acc, f1 = knn_cross_validation(data_vec_8020, labels_8020, k=7)\n",
    "print(f'Accuracy = {acc} - F1-score = {f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fourier (best k = 13 [0.425490, 0.382353])**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.38235294117647056 - F1-score = 0.33473941091588155\n"
     ]
    }
   ],
   "source": [
    "# Tune k using gridsearch on the entire data set\n",
    "# knn_gridsearch(ft_img_data, img_labels, [k for k in range(1,21,2)])\n",
    "\n",
    "# Evaluate with the optimal k (=k) using cross validation\n",
    "acc, f1 = knn_cross_validation(ft_img_data, img_labels, k=13)\n",
    "print(f'Accuracy = {acc} - F1-score = {f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression - BigCats - 80/20\n",
    "**Raw data (best solver = lbfgs, best C = 1)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.3235294117647059 - F1-score = 0.29150326797385623\n"
     ]
    }
   ],
   "source": [
    "# Create the 80/20 split\n",
    "x_train, x_test, y_train, y_test = train_test_split(img_data, img_labels, test_size=0.2, random_state=42, stratify=img_labels)\n",
    "\n",
    "# Tune k using gridsearch on the train set\n",
    "# solvers = [\"newton-cg\", \"lbfgs\", \"liblinear\"]\n",
    "# c_values = [0.1, 1, 10, 100]\n",
    "# logistic_regression_gridsearch(x_train, y_train, solvers, c_values)\n",
    "\n",
    "# Train using the optimal k (=k) and test on the test set\n",
    "acc, f1, pred_labels = logistic_regression(x_train, y_train, x_test, y_test, solver=\"lbfgs\", c_value=1)\n",
    "print(f'Accuracy = {acc} - F1-score = {f1}')\n",
    "\n",
    "# Show a confusion matrix\n",
    "# create_conf_matrix(y_test, pred_labels, title=\"Logistic regression predictions using raw data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SIFT (best solver = x, best C = y)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the 80/20 split\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_vec_8020, labels_8020, test_size=0.2, random_state=42, stratify=labels_8020)\n",
    "\n",
    "# # Tune k using gridsearch on the train set\n",
    "# solvers = [\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\"]\n",
    "# c_values = [0.0001, 0.001, 0.1, 1, 10, 100, 1000, 10000]\n",
    "# logistic_regression_gridsearch(x_train, y_train, solvers, c_values)\n",
    "\n",
    "# # Train using the optimal k (=k) and test on the test set\n",
    "acc, f1, pred_labels = logistic_regression(x_train, y_train, x_test, y_test, solver=\"liblinear\", c_value=10)\n",
    "print(f'Accuracy = {acc} - F1-score = {f1}')\n",
    "\n",
    "# # Show a confusion matrix\n",
    "# # create_conf_matrix(y_test, pred_labels, title=\"Logistic regression predictions using raw data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fourier (best solver = liblinear, best C = 0.1)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.4411764705882353 - F1-score = 0.4169185460745563\n"
     ]
    }
   ],
   "source": [
    "# Create the 80/20 split\n",
    "x_train, x_test, y_train, y_test = train_test_split(ft_img_data, img_labels, test_size=0.2, random_state=42, stratify=img_labels)\n",
    "\n",
    "# Tune k using gridsearch on the train set\n",
    "# solvers = [\"newton-cg\", \"lbfgs\", \"liblinear\"]\n",
    "# c_values = [0.1, 1, 10, 100]\n",
    "# logistic_regression_gridsearch(x_train, y_train, solvers, c_values)\n",
    "\n",
    "# Train using the optimal k (=k) and test on the test set\n",
    "acc, f1, pred_labels = logistic_regression(x_train, y_train, x_test, y_test, solver=\"liblinear\", c_value=0.1)\n",
    "print(f'Accuracy = {acc} - F1-score = {f1}')\n",
    "\n",
    "# Show a confusion matrix\n",
    "# create_conf_matrix(y_test, pred_labels, title=\"Logistic regression predictions using FT data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression - BigCats - Cross Validation\n",
    "**Raw data  (best solver = liblinear, best C = 0.1)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.27647058823529413 - F1-score = 0.25509506833036244\n"
     ]
    }
   ],
   "source": [
    "# Tune the solver and C parameters using gridsearch on the entire data set\n",
    "# solvers = [\"newton-cg\", \"lbfgs\", \"liblinear\"]\n",
    "# c_values = [0.1, 1, 10, 100]\n",
    "# logistic_regression_gridsearch(img_data, img_labels, solvers, c_values)\n",
    "\n",
    "# Evaluate with the optimal k (=k) using cross validation\n",
    "acc, f1 = logistic_regression_cross_validation(img_data, img_labels, solver=\"liblinear\", c_value=0.1)\n",
    "print(f'Accuracy = {acc} - F1-score = {f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SIFT  (best solver = x, best C = y)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.5423076923076924 - F1-score = 0.5105860805860807\n"
     ]
    }
   ],
   "source": [
    "# # Tune the solver and C parameters using gridsearch on the entire data set\n",
    "# solvers = [\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\"]\n",
    "# c_values = [0.1, 1, 10, 100]\n",
    "# logistic_regression_gridsearch(sift_img_data, img_labels, solvers, c_values)\n",
    "\n",
    "# # Evaluate with the optimal k (=k) using cross validation\n",
    "acc, f1 = logistic_regression_cross_validation(data_vec_8020, labels_8020, solver=\"liblinear\", c_value=10)\n",
    "print(f'Accuracy = {acc} - F1-score = {f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fourier (best solver = linear, best C = 0.1)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.39999999999999997 - F1-score = 0.35637000254647316\n"
     ]
    }
   ],
   "source": [
    "# Tune the solver and C parameters using gridsearch on the entire data set\n",
    "# solvers = [\"newton-cg\", \"lbfgs\", \"liblinear\"]\n",
    "# c_values = [0.1, 1, 10, 100]\n",
    "# logistic_regression_gridsearch(ft_img_data, img_labels, solvers, c_values)\n",
    "\n",
    "# Evaluate with the optimal k (=k) using cross validation\n",
    "acc, f1 = logistic_regression_cross_validation(ft_img_data, img_labels, solver=\"liblinear\", c_value=0.1)\n",
    "print(f'Accuracy = {acc} - F1-score = {f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 80/20 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameter Sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing parameter sweep...\n",
      "[0.9813664596273292, 0.9627329192546584, 0.9751552795031055, 0.968944099378882, 0.9875776397515528, 0.9875776397515528, 0.9565217391304348, 0.968944099378882]\n",
      "test accuracy: 0.9875776397515528 for depth 7\n"
     ]
    }
   ],
   "source": [
    "print(\"Performing parameter sweep...\")\n",
    "accuracies = []\n",
    "depths = [3,4,5,6,7,8,9,10]\n",
    "for depth in depths:\n",
    "    print(f\"Trying max depth of {depth}...\", end='\\r')\n",
    "    accuracies.append(decision_tree(num_data, num_labels)[0])\n",
    "print(accuracies)\n",
    "best_depth = depths[accuracies.index(max(accuracies))]\n",
    "print(f\"test accuracy: {max(accuracies)} for depth {depths[accuracies.index(max(accuracies))]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 80/20 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using decision tree classifier on genes raw\n",
      "test accuracy & f1: (0.9813664596273292, 0.981386992454186)\n",
      "using decision tree classifier on genes PCA\n",
      "test accuracy & f1: (0.9006211180124224, 0.898379039885027)\n",
      "using decision tree classifier on genes MI\n",
      "test accuracy & f1: (0.9751552795031055, 0.9753293590801105)\n"
     ]
    }
   ],
   "source": [
    "# Raw data\n",
    "print(\"using decision tree classifier on genes raw\")\n",
    "accuracy, f1_score, y_pred = decision_tree(num_data, num_labels, depth=best_depth)\n",
    "print(f\"test accuracy & f1: {accuracy, f1_score}\")\n",
    "#create_conf_matrix(num_labels, y_pred)\n",
    "\n",
    "# PCA data\n",
    "print(\"using decision tree classifier on genes PCA\")\n",
    "accuracy, f1_score, y_pred = decision_tree(pca_num_data, num_labels, depth=best_depth)\n",
    "print(f\"test accuracy & f1: {accuracy, f1_score}\")\n",
    "#create_conf_matrix(num_labels, y_pred)\n",
    "\n",
    "# MI data\n",
    "print(\"using decision tree classifier on genes MI\")\n",
    "accuracy, f1_score, y_pred = decision_tree(mi_num_data, num_labels, depth=best_depth)\n",
    "print(f\"test accuracy & f1: {accuracy, f1_score}\")\n",
    "#create_conf_matrix(num_labels, y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using decision tree classifier on genes raw with 10-fold\n",
      "0.980 test accuracy with a standard deviation of 0.000\n",
      "0.980 test f1 with a standard deviation of 0.000\n",
      "using decision tree classifier on genes PCA with 10-fold\n",
      "0.916 test accuracy with a standard deviation of 0.000\n",
      "0.916 test f1 with a standard deviation of 0.000\n",
      "using decision tree classifier on genes MI with 10-fold\n",
      "0.984 test accuracy with a standard deviation of 0.000\n",
      "0.984 test f1 with a standard deviation of 0.000\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "# Raw data\n",
    "print(f\"using decision tree classifier on genes raw with {k}-fold\")\n",
    "accuracy, f1 = cross_val_decision_tree(num_data, num_labels, cv=k, depth=best_depth)\n",
    "print(\"%0.3f test accuracy with a standard deviation of %0.3f\" % (accuracy.mean(), accuracy.std()))\n",
    "print(\"%0.3f test f1 with a standard deviation of %0.3f\" % (f1.mean(), f1.std()))\n",
    "\n",
    "# PCA data\n",
    "print(f\"using decision tree classifier on genes PCA with {k}-fold\")\n",
    "accuracy, f1 = cross_val_decision_tree(pca_num_data, num_labels, cv=k, depth=best_depth)\n",
    "print(\"%0.3f test accuracy with a standard deviation of %0.3f\" % (accuracy.mean(), accuracy.std()))\n",
    "print(\"%0.3f test f1 with a standard deviation of %0.3f\" % (f1.mean(), f1.std()))\n",
    "\n",
    "# MI data\n",
    "print(f\"using decision tree classifier on genes MI with {k}-fold\")\n",
    "accuracy, f1 = cross_val_decision_tree(mi_num_data, num_labels, cv=k, depth=best_depth)\n",
    "print(\"%0.3f test accuracy with a standard deviation of %0.3f\" % (accuracy.mean(), accuracy.std()))\n",
    "print(\"%0.3f test f1 with a standard deviation of %0.3f\" % (f1.mean(), f1.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM- BigCats - 80/20\n",
    "**Raw data (best C=10 kernel='rbf',gamma=0.001)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm train start\n",
      "new model saved\n",
      "accuracy on the training subset:0.978\n",
      "accuracy on the test subset:0.265\n",
      "Accuracy = 0.2647058823529412 - F1-score = 0.14695108812755872\n"
     ]
    }
   ],
   "source": [
    "#tuning hyperparameters using grid search\n",
    "#svm_images_gridsearch(img_data, img_labels)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(img_data, img_labels,test_size=0.2,random_state=77,stratify=img_labels)\n",
    "acc, f1, pred_labels =svm_images(X_train, X_test, y_train, y_test,C=10,kernel='rbf',gamma=0.001)\n",
    "print(f'Accuracy = {acc} - F1-score = {f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SIFT  (best C=10 kernel='rbf',gamma=0.001)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm train start\n",
      "new model saved\n",
      "data_vec: (34, 50)\n",
      "image features extration done!\n",
      "accuracy on the training subset:0.978\n",
      "accuracy on the test subset:0.412\n",
      "34\n",
      "acc: 14/34=0.4117647058823529\n",
      "Accuracy = 14 - F1-score = 0.35416101924640825\n"
     ]
    }
   ],
   "source": [
    "#tuning hyperparameters using grid search\n",
    "#svm_images_gridsearch()\n",
    "\n",
    "acc, f1, pred_labels =svm_images(data_vec_8020, X_test_sift, labels_8020, y_test_sift,C=10,kernel='rbf',gamma=0.001)\n",
    "print(f'Accuracy = {acc} - F1-score = {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'acc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21304/1288704299.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Accuracy = {acc} - F1-score = {f1}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'acc' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fourier (best C=10 kernel='rbf',gamma=0.001)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm train start\n",
      "new model saved\n",
      "accuracy on the training subset:0.978\n",
      "accuracy on the test subset:0.265\n",
      "Accuracy = 0.2647058823529412 - F1-score = 0.14695108812755872\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#tuning hyperparameters using grid search\n",
    "#svm_images_gridsearch(ft_img_data, img_labels)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(ft_img_data, img_labels,test_size=0.2,random_state=77,stratify=img_labels)\n",
    "acc, f1, pred_labels =svm_images(X_train, X_test, y_train, y_test,C=10,kernel='rbf',gamma=0.001)\n",
    "print(f'Accuracy = {acc} - F1-score = {f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM - BigCats - Cross Validation\n",
    "**Raw data  (best C=10 kernel='rbf',gamma=0.001)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm train start\n",
      "Accuracy = 0.24705882352941178 - F1-score = 0.1196152290843826\n"
     ]
    }
   ],
   "source": [
    "# Evaluate with the optimal hyperparameters using cross validation\n",
    "acc, f1 = svm_images_cross_val(img_data, img_labels,n_splits = 5,C=10,kernel='rbf',gamma=0.001)\n",
    "print(f'Accuracy = {acc} - F1-score = {f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SIFT  (best C=10 kernel='rbf',gamma=0.001)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tuning hyperparameters using grid search\n",
    "#svm_images_gridsearch()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fourier (best C=10 kernel='rbf',gamma=0.001)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm train start\n",
      "Accuracy = 0.24705882352941178 - F1-score = 0.1196152290843826\n"
     ]
    }
   ],
   "source": [
    "# Evaluate with the optimal hyperparameters using cross validation\n",
    "acc, f1 = svm_images_cross_val(ft_img_data, img_labels,n_splits = 5,C=10,kernel='rbf',gamma=0.001)\n",
    "print(f'Accuracy = {acc} - F1-score = {f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sil: 0.074832954599746, rand: -0.005792197452229299, mi: -0.016625600598516307\n",
      "sil: 0.17258331163052024, rand: 0.12951721178937595, mi: 0.17392170946840202\n",
      "sil: 0.017102167456584, rand: 0.0036489072274082652, mi: 0.0016295791488391991\n"
     ]
    }
   ],
   "source": [
    "# RAW\n",
    "sil_score, rand_score, mi_score = kmeans_train(img_data, img_labels)\n",
    "print(f\"sil: {sil_score}, rand: {rand_score}, mi: {mi_score}\")\n",
    "# SIFT\n",
    "sil_score, rand_score, mi_score = kmeans_train(data_vec_8020, labels_8020)\n",
    "print(f\"sil: {sil_score}, rand: {rand_score}, mi: {mi_score}\")\n",
    "# FT\n",
    "sil_score, rand_score, mi_score = kmeans_train(ft_img_data, img_labels)\n",
    "print(f\"sil: {sil_score}, rand: {rand_score}, mi: {mi_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fuzzy C-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAW NUM\n",
      "fcm.partition_coefficient=0.040000000000024766\n",
      "fcm.partition_entropy_coefficient=0.4643856189773832\n",
      "sil_score=0.12519651029604648\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'to_numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2145/3995943257.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RAW NUM\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuzzy_c_means\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"PCA NUM\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuzzy_c_means\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpca_num_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MI NUM\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/pattern_recog/clustering/fuzzy_c_means.py\u001b[0m in \u001b[0;36mfuzzy_c_means\u001b[0;34m(data, labels, cluster_number, m)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0msil_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msilhouette_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcm_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{sil_score=}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mrand_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madjusted_rand_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcm_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{rand_score=}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mmi_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madjusted_mutual_info_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcm_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'to_numpy'"
     ]
    }
   ],
   "source": [
    "print(\"RAW NUM\")\n",
    "print(fuzzy_c_means(num_data, 5))\n",
    "print(\"PCA NUM\")\n",
    "print(fuzzy_c_means(pca_num_data, 5))\n",
    "print(\"MI NUM\")\n",
    "print(fuzzy_c_means(mi_num_data, 5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from raw_data.data_functions import load_augmented_img_data\n",
    "aug_img_data, aug_img_labels = load_augmented_img_data()\n",
    "\n",
    "from feature_selection.fourier_transform import ft_on_img_data\n",
    "aug_ft_img_data = ft_on_img_data(aug_img_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1729/77005138.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maug_img_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maug_img_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogistic_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"liblinear\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Accuracy = {acc} - F1-score = {f1}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/pattern_recog/classification/logistic_regression.py\u001b[0m in \u001b[0;36mlogistic_regression\u001b[0;34m(train_data, train_labels, test_data, test_labels, solver, c_value)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mpred_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1506\u001b[0m             \u001b[0m_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1508\u001b[0;31m         X, y = self._validate_data(\n\u001b[0m\u001b[1;32m   1509\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    962\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y cannot be None\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 964\u001b[0;31m     X = check_array(\n\u001b[0m\u001b[1;32m    965\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"allow-nan\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    801\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m    112\u001b[0m         ):\n\u001b[1;32m    113\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"infinity\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"NaN, infinity\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    115\u001b[0m                 msg_err.format(\n\u001b[1;32m    116\u001b[0m                     \u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from classification.logistic_regression import logistic_regression\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(aug_img_data, aug_img_labels, test_size=0.2, random_state=42)\n",
    "acc, f1, pred_labels = logistic_regression(x_train, y_train, x_test, y_test, solver=\"liblinear\", c_value=0.1)\n",
    "print(f'Accuracy = {acc} - F1-score = {f1}')\n",
    "\n",
    "# Show a confusion matrix\n",
    "# create_conf_matrix(y_test, pred_labels, title=\"Logistic regression predictions using FT data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(aug_ft_img_data, aug_img_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "acc, f1, pred_labels = logistic_regression(x_train, y_train, x_test, y_test, solver=\"liblinear\", c_value=0.1)\n",
    "print(f'Accuracy = {acc} - F1-score = {f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------\n",
    "*end*"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "42518a910d49e1bcbec57022f51c626a2b80126feae2f4ee4e7dd882ffabe5bf"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
