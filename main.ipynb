{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pattern Recognition pipeline\n",
    "The entire pipeline should be runnable from here.\n",
    "\n",
    "### Genes data\n",
    "**Raw genes data**\n",
    "- Data is expected to be in *raw_data/genes/data.csv*\n",
    "- Labels are expected to be in *raw_data/genes/labels.csv*\n",
    "\n",
    "### Image data\n",
    "**Raw image data**\n",
    "- Animal images are expected to be in *raw_data/BigCats/[Animal]/*\n",
    "\n",
    "### Feature selection\n",
    "- Feature selection functions can be found in *feature_selection/[function].py*\n",
    "\n",
    "### Classification\n",
    "- Classification functions can be found in *classification/[function].py*\n",
    "\n",
    "### Clustering\n",
    "- Clustering functions can be found in *clustering/[function].py*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Boris\\Anaconda3\\lib\\site-packages\\statsmodels\\tools\\_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "## Import ALL required imports\n",
    "\n",
    "# Ignore SKlearn's deprecation warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "# Data imports\n",
    "from raw_data.data_functions import load_num_data, load_img_data\n",
    "from raw_data.data_load_MI_SVM import getImageData\n",
    "\n",
    "# Feature selection imports\n",
    "from feature_selection.pca import pca\n",
    "from feature_selection.MI import MI_feature_select\n",
    "from feature_selection.fourier_transform import ft_on_img_data\n",
    "from feature_selection.edge_detection import edge_detection\n",
    "\n",
    "# Classification imports\n",
    "from classification.knn import knn, knn_gridsearch, knn_cross_validation\n",
    "from classification.svm import svm_genes\n",
    "from classification.decision_tree import decision_tree, cross_val_decision_tree\n",
    "from classification.logistic_regression import logistic_regression, logistic_regression_cross_validation, logistic_regression_gridsearch\n",
    "\n",
    "# Clustering imports\n",
    "from clustering.kmeans import kmeans_train\n",
    "# from clustering.fuzzy_c_means import fuzzy_c_means\n",
    "\n",
    "# Misc imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from visualization.visualization import create_conf_matrix\n",
    "from visualization.visualization import simple_pca_line_plot\n",
    "from visualization.visualization import plot_tsne_num\n",
    "from visualization.visualization import plot_tsne_img\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading num data...\n",
      "Loading img data...\n",
      "Loading img2 data...\n",
      "data load succ\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading num data...\")\n",
    "num_data, num_labels = load_num_data()\n",
    "print(\"Loading img data...\")\n",
    "img_data, img_labels = load_img_data()\n",
    "print(\"Loading img2 data...\")\n",
    "img_data_k, img_labels_k = getImageData(\"../Data-211216/Data/BigCats/\" )  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Data\n",
    "**Create t-SNE embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data_embedded = TSNE(n_components=2, learning_rate='auto', init='random', random_state=0).fit_transform(num_data)\n",
    "img_data_embedded = TSNE(n_components=2, learning_rate='auto', init='random', random_state=0).fit_transform(img_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the t-SNE embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genes data\n",
    "# title = \"t-SNE visualization of the Genes data\"\n",
    "# xlabel = \"t-SNE dimension 1\"\n",
    "# ylabel = \"t-SNE dimension 2\"\n",
    "# plot_tsne_num(num_data_embedded, num_labels, title, xlabel, ylabel)\n",
    "\n",
    "# BigCats data\n",
    "# title = \"t-SNE visualization of the BigCats data\"\n",
    "# xlabel = \"t-SNE dimension 1\"\n",
    "# ylabel = \"t-SNE dimension 2\"\n",
    "# plot_tsne_img(img_data_embedded, img_labels, title, xlabel, ylabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA\n",
    "**Apply PCA to the Genes data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_num_data = pca(num_data.iloc[:,1:])\n",
    "\n",
    "# Plot the cumulative variance explained per number of principal components\n",
    "# simple_pca_line_plot(\n",
    "#     pca_model.explained_variance_ratio_.cumsum()[:], \n",
    "#     title=\"Cum. variance explained / # principal components\",\n",
    "#     ylabel=\"Ratio of variance explained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perform PCA experiment with k-NN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result storage\n",
    "pca_knn_res = []\n",
    "\n",
    "# Perform cross-validated k-NN for each possible number of components\n",
    "for num_components in range(1,802):\n",
    "    selected_data = pca_num_data.iloc[:,:num_components]\n",
    "    acc, f1 = knn_cross_validation(selected_data, num_labels[1], 3)\n",
    "    pca_knn_res.append(acc)\n",
    "\n",
    "# Plot the result\n",
    "# simple_pca_line_plot(\n",
    "#     pca_knn_res[:], \n",
    "#     title=\"Test accuracy per number of principal components\",\n",
    "#     ylabel=\"Test accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reduce PCA data to the most useful components (=79)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pca_num_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-05ea5ca0a4a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpca_num_data_red\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpca_num_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m80\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'pca_num_data' is not defined"
     ]
    }
   ],
   "source": [
    "pca_num_data_red = pca_num_data.iloc[:,:80]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature selection start\n",
      "Feature drop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abe/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "478 features whose MI score over threshold are selected from 20531 features\n",
      "feature selection end\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mi_num_data=MI_feature_select(num_data,num_labels,thre=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fourier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_img_data = ft_on_img_data(img_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contour Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Boris\\Anaconda3\\lib\\site-packages\\skimage\\util\\dtype.py:135: UserWarning: Possible precision loss when converting from int64 to float64\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n"
     ]
    }
   ],
   "source": [
    "edge_img_data = edge_detection(img_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-NN - Genes - 80/20 split\n",
    "**Raw data (best k = 15 [0.998090, 0.998437])**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.9937888198757764 - F1-score = 0.993758020635491\n"
     ]
    }
   ],
   "source": [
    "# Create the 80/20 split\n",
    "x_train, x_test, y_train, y_test = train_test_split(num_data, num_labels, test_size=0.2, random_state=42, stratify=num_labels)\n",
    "\n",
    "# Tune k using gridsearch on the train set\n",
    "# knn_gridsearch(x_train, y_train[1], [k for k in range(1,21,2)])\n",
    "\n",
    "# Train using the optimal k (=5) and test on the test set\n",
    "acc, f1, pred_labels = knn(x_train, y_train[1], x_test, y_test[1], k=15)\n",
    "print(f'Accuracy = {acc} - F1-score = {f1}')\n",
    "\n",
    "# Show a confusion matrix\n",
    "# create_conf_matrix(y_test[1], pred_labels,  title=\"k-NN predictions using raw data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PCA (best k = 13 [0.998785, 0.998437])**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.9813664596273292 - F1-score = 0.9811987061061624\n"
     ]
    }
   ],
   "source": [
    "# Create the 80/20 split\n",
    "x_train, x_test, y_train, y_test = train_test_split(pca_num_data_red, num_labels, test_size=0.2, random_state=42, stratify=num_labels)\n",
    "\n",
    "# Tune k using gridsearch on the train set\n",
    "# knn_gridsearch(x_train, y_train[1], [k for k in range(1,21,2)])\n",
    "\n",
    "# Train using the optimal k (=k) and test on the test set\n",
    "acc, f1, pred_labels = knn(x_train, y_train[1], x_test, y_test[1], k=13)\n",
    "print(f'Accuracy = {acc} - F1-score = {f1}')\n",
    "\n",
    "# Show a confusion matrix\n",
    "# create_conf_matrix(y_test[1], pred_labels,  title=\"k-NN predictions using PCA data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mutual Information (best k = 5 [0.998437, 0.998437])**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.9937888198757764 - F1-score = 0.993758020635491\n"
     ]
    }
   ],
   "source": [
    "# Create the 80/20 split\n",
    "x_train, x_test, y_train, y_test = train_test_split(mi_num_data, num_labels, test_size=0.2, random_state=42, stratify=num_labels)\n",
    "\n",
    "# Tune k using gridsearch on the train set\n",
    "# knn_gridsearch(x_train, y_train[1], [k for k in range(1,21,2)])\n",
    "\n",
    "# Train using the optimal k (=k) and test on the test set\n",
    "acc, f1, pred_labels = knn(x_train, y_train[1], x_test, y_test[1], k=5)\n",
    "print(f'Accuracy = {acc} - F1-score = {f1}')\n",
    "\n",
    "# Show a confusion matrix\n",
    "# create_conf_matrix(y_test[1], pred_labels, title=\"k-NN predictions using MI data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-NN - Genes - Cross Validation\n",
    "**Raw data (best k = 3,5,7,9 [0.998752, 0.998750])**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.99875 - F1-score = 0.9987370977534912\n"
     ]
    }
   ],
   "source": [
    "# Tune k using gridsearch on the entire data set\n",
    "# knn_gridsearch(num_data, num_labels[1], [k for k in range(1,21,2)])\n",
    "\n",
    "# Evaluate with the optimal k (=k) using cross validation\n",
    "acc, f1 = knn_cross_validation(num_data, num_labels[1], k=3)\n",
    "print(f'Accuracy = {acc} - F1-score = {f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PCA (best k = 3 [0.997503, 0.997500])**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.9974999999999999 - F1-score = 0.9974441687344914\n"
     ]
    }
   ],
   "source": [
    "# Tune k using gridsearch on the entire data set\n",
    "# knn_gridsearch(pca_num_data_red, num_labels[1], [k for k in range(1,21,2)])\n",
    "\n",
    "# Evaluate with the optimal k (=k) using cross validation\n",
    "acc, f1 = knn_cross_validation(pca_num_data_red, num_labels[1], k=3)\n",
    "print(f'Accuracy = {acc} - F1-score = {f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mutual Information (best k = 5-19 [0.997503, 0.997500])**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.9974999999999999 - F1-score = 0.9974441687344914\n"
     ]
    }
   ],
   "source": [
    "# Tune k using gridsearch on the entire data set\n",
    "# knn_gridsearch(mi_num_data, num_labels[1], [k for k in range(1,21,2)])\n",
    "\n",
    "# Evaluate with the optimal k (=k) using cross validation\n",
    "acc, f1 = knn_cross_validation(mi_num_data, num_labels[1], k=5)\n",
    "print(f'Accuracy = {acc} - F1-score = {f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-NN - BigCats - 80/20 split\n",
    "**Raw data (best k = 3 [0.520405, 0.235714])**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.17647058823529413 - F1-score = 0.16657329598506068\n"
     ]
    }
   ],
   "source": [
    "# Create the 80/20 split\n",
    "x_train, x_test, y_train, y_test = train_test_split(img_data, img_labels, test_size=0.2, random_state=42, stratify=img_labels)\n",
    "\n",
    "# Tune k using gridsearch on the train set\n",
    "# knn_gridsearch(x_train, y_train, [k for k in range(1,21,2)])\n",
    "\n",
    "# Train using the optimal k (=k) and test on the test set\n",
    "acc, f1, pred_labels = knn(x_train, y_train, x_test, y_test, k=3)\n",
    "print(f'Accuracy = {acc} - F1-score = {f1}')\n",
    "\n",
    "# Show a confusion matrix\n",
    "# create_conf_matrix(y_test, pred_labels, title=\"k-NN predictions using raw data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SIFT (best k = k)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the 80/20 split\n",
    "# x_train, x_test, y_train, y_test = train_test_split(ft_img_data, img_labels, test_size=0.2, random_state=42, stratify=img_labels)\n",
    "\n",
    "# # Tune k using gridsearch on the train set\n",
    "# # knn_gridsearch(x_train, y_train, [k for k in range(1,21,2)])\n",
    "\n",
    "# # Train using the optimal k (=5) and test on the test set\n",
    "# acc, f1, pred_labels = knn(x_train, y_train, x_test, y_test, k=17)\n",
    "\n",
    "# # Show a confusion matrix\n",
    "# create_conf_matrix(y_test, pred_labels, title=\"k-NN predictions using SIFT data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fourier (best k = 17 [0.361922, 0.300549])**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.4411764705882353 - F1-score = 0.3927932576539388\n"
     ]
    }
   ],
   "source": [
    "# Create the 80/20 split\n",
    "x_train, x_test, y_train, y_test = train_test_split(ft_img_data, img_labels, test_size=0.2, random_state=42, stratify=img_labels)\n",
    "\n",
    "# Tune k using gridsearch on the train set\n",
    "# knn_gridsearch(x_train, y_train, [k for k in range(1,21,2)])\n",
    "\n",
    "# Train using the optimal k (=5) and test on the test set\n",
    "acc, f1, pred_labels = knn(x_train, y_train, x_test, y_test, k=17)\n",
    "print(f'Accuracy = {acc} - F1-score = {f1}')\n",
    "\n",
    "# Show a confusion matrix\n",
    "# create_conf_matrix(y_test, pred_labels, title=\"k-NN predictions using FT data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-NN - BigCats - Cross Validation\n",
    "**Raw data (best k = 7 [0.384967, 0.247059])**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.24705882352941178 - F1-score = 0.2068569992099404\n"
     ]
    }
   ],
   "source": [
    "# Tune k using gridsearch on the entire data set\n",
    "# knn_gridsearch(img_data, img_labels, [k for k in range(1,21,2)])\n",
    "\n",
    "# Evaluate with the optimal k (=k) using cross validation\n",
    "acc, f1 = knn_cross_validation(img_data, img_labels, k=7)\n",
    "print(f'Accuracy = {acc} - F1-score = {f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SIFT (best k = k)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fourier (best k = 13 [0.425490, 0.382353])**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.38235294117647056 - F1-score = 0.33473941091588155\n"
     ]
    }
   ],
   "source": [
    "# Tune k using gridsearch on the entire data set\n",
    "# knn_gridsearch(ft_img_data, img_labels, [k for k in range(1,21,2)])\n",
    "\n",
    "# Evaluate with the optimal k (=k) using cross validation\n",
    "acc, f1 = knn_cross_validation(ft_img_data, img_labels, k=13)\n",
    "print(f'Accuracy = {acc} - F1-score = {f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression - BigCats - 80/20\n",
    "**Raw data (best solver = lbfgs, best C = 1)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.3235294117647059 - F1-score = 0.29150326797385623\n"
     ]
    }
   ],
   "source": [
    "# Create the 80/20 split\n",
    "x_train, x_test, y_train, y_test = train_test_split(img_data, img_labels, test_size=0.2, random_state=42, stratify=img_labels)\n",
    "\n",
    "# Tune k using gridsearch on the train set\n",
    "# solvers = [\"newton-cg\", \"lbfgs\", \"liblinear\"]\n",
    "# c_values = [0.1, 1, 10, 100]\n",
    "# logistic_regression_gridsearch(x_train, y_train, solvers, c_values)\n",
    "\n",
    "# Train using the optimal k (=k) and test on the test set\n",
    "acc, f1, pred_labels = logistic_regression(x_train, y_train, x_test, y_test, solver=\"lbfgs\", c_value=1)\n",
    "print(f'Accuracy = {acc} - F1-score = {f1}')\n",
    "\n",
    "# Show a confusion matrix\n",
    "# create_conf_matrix(y_test, pred_labels, title=\"Logistic regression predictions using raw data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SIFT (best solver = x, best C = y)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the 80/20 split\n",
    "# x_train, x_test, y_train, y_test = train_test_split(sift_img_data, img_labels, test_size=0.2, random_state=42, stratify=img_labels)\n",
    "\n",
    "# # Tune k using gridsearch on the train set\n",
    "# solvers = [\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\"]\n",
    "# c_values = [0.0001, 0.001, 0.1, 1, 10, 100, 1000, 10000]\n",
    "# logistic_regression_gridsearch(x_train, y_train, solvers, c_values)\n",
    "\n",
    "# # Train using the optimal k (=k) and test on the test set\n",
    "# # acc, f1, pred_labels = logistic_regression(x_train, y_train, x_test, y_test, solver=\"newton-cg\", c_value=10)\n",
    "# # print(f'Accuracy = {acc} - F1-score = {f1}')\n",
    "\n",
    "# # Show a confusion matrix\n",
    "# # create_conf_matrix(y_test, pred_labels, title=\"Logistic regression predictions using raw data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fourier (best solver = liblinear, best C = 0.1)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.4411764705882353 - F1-score = 0.4169185460745563\n"
     ]
    }
   ],
   "source": [
    "# Create the 80/20 split\n",
    "x_train, x_test, y_train, y_test = train_test_split(ft_img_data, img_labels, test_size=0.2, random_state=42, stratify=img_labels)\n",
    "\n",
    "# Tune k using gridsearch on the train set\n",
    "# solvers = [\"newton-cg\", \"lbfgs\", \"liblinear\"]\n",
    "# c_values = [0.1, 1, 10, 100]\n",
    "# logistic_regression_gridsearch(x_train, y_train, solvers, c_values)\n",
    "\n",
    "# Train using the optimal k (=k) and test on the test set\n",
    "acc, f1, pred_labels = logistic_regression(x_train, y_train, x_test, y_test, solver=\"liblinear\", c_value=0.1)\n",
    "print(f'Accuracy = {acc} - F1-score = {f1}')\n",
    "\n",
    "# Show a confusion matrix\n",
    "# create_conf_matrix(y_test, pred_labels, title=\"Logistic regression predictions using FT data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression - BigCats - Cross Validation\n",
    "**Raw data  (best solver = liblinear, best C = 0.1)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.27647058823529413 - F1-score = 0.25509506833036244\n"
     ]
    }
   ],
   "source": [
    "# Tune the solver and C parameters using gridsearch on the entire data set\n",
    "# solvers = [\"newton-cg\", \"lbfgs\", \"liblinear\"]\n",
    "# c_values = [0.1, 1, 10, 100]\n",
    "# logistic_regression_gridsearch(img_data, img_labels, solvers, c_values)\n",
    "\n",
    "# Evaluate with the optimal k (=k) using cross validation\n",
    "acc, f1 = logistic_regression_cross_validation(img_data, img_labels, solver=\"liblinear\", c_value=0.1)\n",
    "print(f'Accuracy = {acc} - F1-score = {f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SIFT  (best solver = x, best C = y)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Tune the solver and C parameters using gridsearch on the entire data set\n",
    "# solvers = [\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\"]\n",
    "# c_values = [0.1, 1, 10, 100]\n",
    "# logistic_regression_gridsearch(sift_img_data, img_labels, solvers, c_values)\n",
    "\n",
    "# # Evaluate with the optimal k (=k) using cross validation\n",
    "# acc, f1 = logistic_regression_cross_validation(sift_img_data, img_labels, solver=\"\", c_value=10)\n",
    "# print(f'Accuracy = {acc} - F1-score = {f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fourier (best solver = linear, best C = 0.1)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.39999999999999997 - F1-score = 0.35637000254647316\n"
     ]
    }
   ],
   "source": [
    "# Tune the solver and C parameters using gridsearch on the entire data set\n",
    "# solvers = [\"newton-cg\", \"lbfgs\", \"liblinear\"]\n",
    "# c_values = [0.1, 1, 10, 100]\n",
    "# logistic_regression_gridsearch(ft_img_data, img_labels, solvers, c_values)\n",
    "\n",
    "# Evaluate with the optimal k (=k) using cross validation\n",
    "acc, f1 = logistic_regression_cross_validation(ft_img_data, img_labels, solver=\"liblinear\", c_value=0.1)\n",
    "print(f'Accuracy = {acc} - F1-score = {f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 80/20 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameter Sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing parameter sweep...\n",
      "[0.9813664596273292, 0.9627329192546584, 0.9751552795031055, 0.968944099378882, 0.9875776397515528, 0.9875776397515528, 0.9565217391304348, 0.968944099378882]\n",
      "test accuracy: 0.9875776397515528 for depth 7\n"
     ]
    }
   ],
   "source": [
    "print(\"Performing parameter sweep...\")\n",
    "accuracies = []\n",
    "depths = [3,4,5,6,7,8,9,10]\n",
    "for depth in depths:\n",
    "    print(f\"Trying max depth of {depth}...\", end='\\r')\n",
    "    accuracies.append(decision_tree(num_data, num_labels)[0])\n",
    "print(accuracies)\n",
    "best_depth = depths[accuracies.index(max(accuracies))]\n",
    "print(f\"test accuracy: {max(accuracies)} for depth {depths[accuracies.index(max(accuracies))]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 80/20 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using decision tree classifier on genes raw\n",
      "test accuracy & f1: (0.9813664596273292, 0.981386992454186)\n",
      "using decision tree classifier on genes PCA\n",
      "test accuracy & f1: (0.9006211180124224, 0.898379039885027)\n",
      "using decision tree classifier on genes MI\n",
      "test accuracy & f1: (0.9751552795031055, 0.9753293590801105)\n"
     ]
    }
   ],
   "source": [
    "# Raw data\n",
    "print(\"using decision tree classifier on genes raw\")\n",
    "accuracy, f1_score, y_pred = decision_tree(num_data, num_labels, depth=best_depth)\n",
    "print(f\"test accuracy & f1: {accuracy, f1_score}\")\n",
    "#create_conf_matrix(num_labels, y_pred)\n",
    "\n",
    "# PCA data\n",
    "print(\"using decision tree classifier on genes PCA\")\n",
    "accuracy, f1_score, y_pred = decision_tree(pca_num_data, num_labels, depth=best_depth)\n",
    "print(f\"test accuracy & f1: {accuracy, f1_score}\")\n",
    "#create_conf_matrix(num_labels, y_pred)\n",
    "\n",
    "# MI data\n",
    "print(\"using decision tree classifier on genes MI\")\n",
    "accuracy, f1_score, y_pred = decision_tree(mi_num_data, num_labels, depth=best_depth)\n",
    "print(f\"test accuracy & f1: {accuracy, f1_score}\")\n",
    "#create_conf_matrix(num_labels, y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using decision tree classifier on genes raw with 10-fold\n",
      "0.980 test accuracy with a standard deviation of 0.000\n",
      "0.980 test f1 with a standard deviation of 0.000\n",
      "using decision tree classifier on genes PCA with 10-fold\n",
      "0.916 test accuracy with a standard deviation of 0.000\n",
      "0.916 test f1 with a standard deviation of 0.000\n",
      "using decision tree classifier on genes MI with 10-fold\n",
      "0.984 test accuracy with a standard deviation of 0.000\n",
      "0.984 test f1 with a standard deviation of 0.000\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "# Raw data\n",
    "print(f\"using decision tree classifier on genes raw with {k}-fold\")\n",
    "accuracy, f1 = cross_val_decision_tree(num_data, num_labels, cv=k, depth=best_depth)\n",
    "print(\"%0.3f test accuracy with a standard deviation of %0.3f\" % (accuracy.mean(), accuracy.std()))\n",
    "print(\"%0.3f test f1 with a standard deviation of %0.3f\" % (f1.mean(), f1.std()))\n",
    "\n",
    "# PCA data\n",
    "print(f\"using decision tree classifier on genes PCA with {k}-fold\")\n",
    "accuracy, f1 = cross_val_decision_tree(pca_num_data, num_labels, cv=k, depth=best_depth)\n",
    "print(\"%0.3f test accuracy with a standard deviation of %0.3f\" % (accuracy.mean(), accuracy.std()))\n",
    "print(\"%0.3f test f1 with a standard deviation of %0.3f\" % (f1.mean(), f1.std()))\n",
    "\n",
    "# MI data\n",
    "print(f\"using decision tree classifier on genes MI with {k}-fold\")\n",
    "accuracy, f1 = cross_val_decision_tree(mi_num_data, num_labels, cv=k, depth=best_depth)\n",
    "print(\"%0.3f test accuracy with a standard deviation of %0.3f\" % (accuracy.mean(), accuracy.std()))\n",
    "print(\"%0.3f test f1 with a standard deviation of %0.3f\" % (f1.mean(), f1.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 80/20 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 80/20 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm train start\n",
      "new model saved\n",
      "accuracy on the training subset:1.000\n",
      "accuracy on the test subset:0.994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abe/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "svm_genes(mi_num_data,num_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: -680557997.8520824\n",
      "MI_evaluate_score_of_test: 0.22804604671270068\n",
      "----------------k= 0 ----------------\n",
      "['Tiger' 'Cheetah' 'Tiger' 'Tiger' 'Tiger' 'Lion' 'Tiger' 'Cheetah'\n",
      " 'Jaguar' 'Cheetah' 'Cheetah' 'Lion' 'Tiger' 'Tiger' 'Leopard' 'Lion']\n",
      "----------------k= 1 ----------------\n",
      "['Jaguar' 'Jaguar' 'Jaguar' 'Tiger' 'Cheetah' 'Cheetah' 'Tiger' 'Leopard'\n",
      " 'Cheetah' 'Cheetah' 'Jaguar' 'Lion' 'Lion' 'Cheetah' 'Jaguar' 'Leopard'\n",
      " 'Lion' 'Leopard' 'Jaguar' 'Jaguar' 'Cheetah' 'Lion' 'Tiger' 'Jaguar'\n",
      " 'Leopard']\n",
      "----------------k= 2 ----------------\n",
      "['Leopard' 'Lion' 'Tiger' 'Tiger' 'Tiger' 'Lion' 'Cheetah' 'Leopard'\n",
      " 'Lion' 'Lion' 'Jaguar']\n",
      "----------------k= 3 ----------------\n",
      "['Lion' 'Tiger' 'Lion' 'Tiger' 'Cheetah' 'Tiger' 'Leopard' 'Jaguar'\n",
      " 'Leopard' 'Tiger' 'Cheetah' 'Lion' 'Jaguar' 'Lion' 'Cheetah' 'Cheetah'\n",
      " 'Leopard' 'Lion' 'Leopard' 'Lion' 'Leopard' 'Lion' 'Leopard' 'Tiger'\n",
      " 'Tiger']\n",
      "----------------k= 4 ----------------\n",
      "['Lion' 'Jaguar' 'Cheetah' 'Tiger' 'Lion' 'Cheetah' 'Cheetah' 'Lion'\n",
      " 'Tiger' 'Cheetah' 'Leopard' 'Tiger' 'Cheetah' 'Leopard' 'Jaguar' 'Tiger'\n",
      " 'Leopard']\n"
     ]
    }
   ],
   "source": [
    "kmeans_train(img_data_k, img_labels_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fuzzy C-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAW NUM\n",
      "fcm.partition_coefficient=0.040000000000048164\n",
      "fcm.partition_entropy_coefficient=0.46438561897729874\n",
      "PCA NUM\n",
      "fcm.partition_coefficient=0.040000000000009125\n",
      "fcm.partition_entropy_coefficient=0.4643856189774396\n",
      "MI NUM\n",
      "fcm.partition_coefficient=0.040000000000133616\n",
      "fcm.partition_entropy_coefficient=0.46438561897699054\n",
      "RAW IMG\n",
      "fcm.partition_coefficient=0.04000000000005647\n",
      "fcm.partition_entropy_coefficient=0.4643856189772687\n",
      "FT IMG\n",
      "fcm.partition_coefficient=0.040000000000025245\n",
      "fcm.partition_entropy_coefficient=0.46438561897738134\n"
     ]
    }
   ],
   "source": [
    "print(\"RAW NUM\")\n",
    "fuzzy_c_means(num_data, 3)\n",
    "print(\"PCA NUM\")\n",
    "fuzzy_c_means(pca_num_data, 3)\n",
    "print(\"MI NUM\")\n",
    "fuzzy_c_means(mi_num_data, 3)\n",
    "\n",
    "print(\"RAW IMG\")\n",
    "fuzzy_c_means(img_data, 3)\n",
    "print(\"FT IMG\")\n",
    "fuzzy_c_means(ft_img_data, 3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------\n",
    "*end*"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "42518a910d49e1bcbec57022f51c626a2b80126feae2f4ee4e7dd882ffabe5bf"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
